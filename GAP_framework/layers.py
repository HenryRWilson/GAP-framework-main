import torch
import torch.nn as nn 
import torch.nn.functional as F
import random 
from torch.nn import init
from utils import featureless_random_graph,get_feature_func,get_neigh_list
"""
Here we will implement the GraphSAGE layer and a graph convolutional layer.
                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^ TODO
Recommend reading 
The original GraphSAGE paper:
https://cs.stanford.edu/people/jure/pubs/graphsage-nips17.pdf

Influenced heavily by https://github.com/williamleif/graphsage-simple/

TERMINOLOGY:
    A graph is described by a set G = {V,E} of nodes and edges.
    A representation of a node is any feature associated to that node. I avoid
    using 'feature' generally here as this definition also applies to neural
    network produced features of nodes ie. trainable embeddings.
    - In this case the representation is initially the node features (PCA) for
      layer one, and for later layers is the output of the previous layer.

We implement a GraphSAGE layer as 2 distinct objects:
1. A layer-like Encoder class, with an associated weight matrix W and activation
   function. This level takes a representation of a node and combines it with
   another representation generated by the Aggregator.
2. An Aggregator class which generates a representation of a node from it's
   neighbours representations in the previous layer. Can be seen as a learnt
   representation producing function which can take some complex-NN forms if needed.
This two object layout is useful as the aggregator functions can vary.

TODO : Can implement more aggregators
"""
class MeanAggregator(nn.Module):
    """
    Aggregates a node's embedding using mean of neighbors' embeddings.
    """
    def __init__(self,features,cuda=False,verbose=False,
                    gcn=False):
        """
        Inits an aggregator for this graph.
        features -- A function mapping a long tensor of node ids to 
                    a float tensor of feature values.
        cuda     -- Whether to cast tensors in this scope to the GPU
        """
        super(MeanAggregator,self).__init__()

        self.features = features
        self.cuda = cuda
        self.verbose = verbose
        self.gcn = gcn

    def forward(self, nodes, neighbours, num_sample=5):
        """
        The aggregator needs:
        nodes -- list of nodes in a batch
        neighbours -- list of sets, i-th set is i-th nodes neighbours.
        num_sample -- n_samples to draw from the neighbourhood
                   ^> None means use full neighbourhood!
        """
        # Making these pointers makes them faster 
        _set = set
        _sample = random.sample 
        # First let's find neighbours we need to sample
        # We sample a distinct set for each node.
        if num_sample is not None: # if performing sampling
            samp_neighs = []
            for neighbourhood in neighbours:
                if len(neighbourhood) >= num_sample:
                    # If there are more neighbours than samples in a
                    # neighbourhood we sample it
                    samp_neighs.append(_set(_sample(neighbourhood,num_sample)))
                else: # If less then we just take as is
                    samp_neighs.append(neighbourhood)
        else: 
            samp_neighs = neighbours 
        # Add self loops 
        if self.gcn:
            samp_neighs = [samp_neigh + set([nodes[i]]) for i, samp_neigh in
                           enumerate(samp_neighs)]
        # Find all unique nodes
        unique_nodes_list = list(set.union(*samp_neighs)) 
        # Assign all current nodes an index accessed by their node_id (n) 
        # in a dict.
        unique_nodes = {n:i for i,n in enumerate(unique_nodes_list)}
        # Create a mask which will allow the layer to only show data from connected
        # nodes to other connected nodes. This has an index for each node in the
        # batch with an index for each unique node it may be connected to
        mask = torch.zeros(len(samp_neighs),len(unique_nodes))
        # Next we find the indices of the maks for the edges
        # (This is essentially a condensed adjacency matrix)
        column_indices = []
        row_indices = []
        # samp_neighs is an list of sets of indices representing edges
        for i,connected_nodes in enumerate(samp_neighs):
            n_neighs = len(connected_nodes)
            for n in connected_nodes:
                # Network Ordering -> Batch Ordering
                column_indices.append(unique_nodes[n])
            # Associated indices
            for j in range(n_neighs):
                row_indices.append(i)
        # Set the value of these nodes to 1
        mask[row_indices,column_indices] = 1
        # Send to GPU if needed
        if self.cuda:
            mask = mask.cuda()
        # Calculate the number of neigbours for each node
        num_neigh = mask.sum(1,keepdim=True)
        # Divide each 1 in the mask by the number of neighbours
        # This is a step towards calculating the mean!
        mask = mask.div(num_neigh)
        # Get the features of all nodes involved:
        # !!! This call recursively calls all previous aggregators in the
        # !!! training process
        if self.cuda:
            embed_matrix = self.features(torch.LongTensor(unique_nodes_list).cuda())
        else:
            embed_matrix = self.features(torch.LongTensor(unique_nodes_list))
        # Matrix multiplication here produces the aggregate averaged features
        to_feats = mask.mm(embed_matrix.float())
        return to_feats

class Encoder(nn.Module):
    """
    Encodes nodes.

    Feature_dim can be seen as input shape.
    Embed_dim can be seen as output shape.
    Features is a function that returns a representation of a node
    """ 
    def __init__(self, features, feature_dim, 
            embed_dim, adj_lists, aggregator,
            num_sample=10,
            base_model=None, cuda=False, 
            feature_transform=False,verbose=False): 
        super(Encoder, self).__init__()

        self.features = features
        self.feat_dim = feature_dim
        self.adj_lists = adj_lists
        self.aggregator = aggregator
        self.num_sample = num_sample
        self.verbose = verbose
        self.activation = "relu" # TODO : Implement other functions
        if base_model != None:
            self.base_model = base_model
        self.embed_dim = embed_dim
        self.cuda = cuda
        self.aggregator.cuda = cuda
        # The weight is the learnt parameter of this layer used to highlight
        # the important regions of the incoming representation.
        # It is 2 x feat_dim as it uses two representations at once, the local
        # and neighbourhood aggregated.
        self.weight = nn.Parameter(
                torch.FloatTensor(embed_dim, 2 * self.feat_dim))
        init.xavier_uniform_(self.weight)

    def forward(self, nodes):
        """
        Generates embeddings for a batch of nodes.
        nodes     -- list of nodes
        """
        # Calculate aggregated representations
        neigh_feats = self.aggregator.forward(nodes, 
                                              [self.adj_lists[int(node)] for 
                                               node in nodes], 
                                              self.num_sample)
        # Cast these to GPU if necessary
        if self.cuda:
            self_feats = self.features(torch.LongTensor(nodes).cuda())
        else:
            self_feats = self.features(torch.LongTensor([*nodes]))
        # Concatenate the layers previous representation with current
        combined = torch.cat([self_feats, neigh_feats], dim=1)
        # Feed this through an activation function
        if self.activation == "relu":
            combined = F.relu(self.weight.mm(combined.t().float()))
        return combined

class GraphSAGEEncoder(nn.Module):
    """
    Encodes nodes.

    Feature_dim can be seen as input shape.
    Embed_dim can be seen as output shape.
    Features is a function that returns a representation of a node
    """ 
    def __init__(self, features, feature_dim, 
            embed_dim, adj_lists, aggregator,
            num_sample=10,
            base_model=None, cuda=False, 
            feature_transform=False,verbose=False): 
        super(Encoder, self).__init__()

        self.features = features
        self.feat_dim = feature_dim
        self.adj_lists = adj_lists
        self.aggregator = aggregator
        self.num_sample = num_sample
        self.verbose = verbose
        self.activation = "relu" # TODO : Implement other functions
        if base_model != None:
            self.base_model = base_model
        self.embed_dim = embed_dim
        self.cuda = cuda
        self.aggregator.cuda = cuda
        self.weight = nn.Parameter(
                torch.FloatTensor(embed_dim, 2 * self.feat_dim))
        init.xavier_uniform_(self.weight)

    def forward(self, nodes):
        """
        Generates embeddings for a batch of nodes.
        nodes     -- list of nodes.

        In the graph sage implementation they use a maxpooling on the
        neighbourhood state along with including the addition of the aggregated
        state into the activation function input.

        TODO: Implement max pooling.
        """
        # Calculate aggregated representations
        neigh_feats = self.aggregator.forward(nodes, 
                                              [self.adj_lists[int(node)] for 
                                               node in nodes], 
                                              self.num_sample)
        # Cast these to GPU if necessary
        if self.cuda:
            self_feats = self.features(torch.LongTensor(nodes).cuda())
        else:
            self_feats = self.features(torch.LongTensor([*nodes]))
        # Concatenate the layers previous representation with current
        combined = torch.cat([self_feats, neigh_feats], dim=1)
        # Feed this through an activation function
        if self.activation == "relu":
            combined = F.relu(self.weight.mm(combined.t().float())+neigh_feats)
        return combined
"""
Unit tests!
"""
if __name__ == '__main__':
    adj, degrees, feats = featureless_random_graph(100)
    adj_list = get_neigh_list(adj)
    node_list = [*range(adj.shape[0])]
    features = get_feature_func(node_list,feats)
    test_agg = MeanAggregator(features,cuda=True)
    test_layer = Encoder(features, 
                         feats.shape[1],
                         5, 
                         adj_list,
                         test_agg,
                        num_sample=None)
    # Attempt to feed a graph through the layer
    for i in range(len(adj_list)):
        n_con = len(adj_list[i])
        print("n_connections:", n_con)
        print(adj_list[i])
        if n_con == 0:
            print("No connections! Skipping...")
            continue
        x = test_layer(adj_list[i]) # Feed this a node neighbour list
        print(f"Success for {i}!")
        print(x.shape)
        print()
